
网络爬虫的尺寸
1：爬取网页，玩转网页：
小规模，数据量小，爬取速度不敏感，主要使用requests库
2：爬取网站，系列网站：
中规模，数据规模较大，爬取速度敏感，主要使用scrapy库
3：爬取全网：
大规模，搜索引擎，爬取速度关键，定制开发

网络爬虫引发的问题：

1：网络爬虫“性能骚扰”：
web服务器默认接收人类访问，受限于编写水平和目的，网络爬虫将会为web服务器带来巨大的资源开销
2：网络爬虫的法律风险：
服务器上的数据有产权归属，网络爬虫获取数据后牟利将带来法律风险
3：网络爬虫的隐私泄露：
网络爬虫可能具备突破简单访问控制的能力，获得被保护数据，从而泄露个人隐私

网络爬虫的限制：
1：来源审查：判断User_Agent进行限制：
检查来访HTTP协议头的User_Agent域，只响应浏览器或友好爬虫的访问
2：发布公告：Robots协议：
告知所有爬虫网站的爬取策略，要求爬虫遵守



Robots 协议：Robots Exclusion Standard，网络爬虫排除标准
作用：网站告知网络爬虫哪些页面可以抓取，哪些步行
形式：在网站根目录侠的robots.txt文件
举例：https://www.jd.com/robots.txt  京东的Robots 协议
Robots协议基本语法：
# 注释，*代表所有，/代表根目录 User‐agent: *  Disallow: /

Robots 协议的使用：
网络爬虫：自动或人工识别robots.txt，再进行内容爬取
约束性：
Robots协议是建议但非约束性，网络爬虫可以不遵守，但存在法律风险
